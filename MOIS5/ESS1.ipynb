{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled98.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtLEQwodl42M/djzvA+NKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meriemdouider1/mois1-mois2/blob/main/MOIS5/ESS1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba0Ulyu5ycf2"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, r2_score\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import datasets, metrics, model_selection, svm\n",
        "import numpy as np\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import datasets, metrics, model_selection, svm\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZpW8fsXFrh3"
      },
      "outputs": [],
      "source": [
        "Cl1 = '/content/cs-longia.xlsx' \n",
        "data=pd.read_excel(Cl1, sheet_name=0,header=0,index_col=False, keep_default_na=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "_GMyLG-Fqr7k",
        "outputId": "d930cbf4-bb5b-42ab-a0b1-f2750de4babb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        X_long      Y_lat  Cs_longia    Bovins    Volaille   Caprins  \\\n",
              "0   -15.911420  23.794740          1  0.000000    0.000000  0.000000   \n",
              "1   -13.188370  27.132950          1  0.000214    0.000000  0.063449   \n",
              "2   -13.188370  27.132950          1  0.000214    0.000000  0.063449   \n",
              "3   -13.185620  27.157940          0  0.000000    0.000000  0.000000   \n",
              "4   -13.167180  27.157730          0  0.000000    0.000000  0.000000   \n",
              "..         ...        ...        ...       ...         ...       ...   \n",
              "249  -5.366667  35.766667          1  8.495770  105.550156  8.691405   \n",
              "250  -5.816667  35.783333          1  0.000000    0.000000  0.000000   \n",
              "251  -5.366667  35.833333          1  7.411978  111.459663  7.364459   \n",
              "252  -5.558611  35.841944          1  5.696193    5.641273  0.602672   \n",
              "253  -5.483333  35.900000          1  6.839514   15.082421  0.782080   \n",
              "\n",
              "         Ovins   Equides  Coniferes  ZoneAride  ...  Vent_Mars  Vent_Avril  \\\n",
              "0     0.000000  0.624435          0         97  ...        6.1         6.9   \n",
              "1     0.034352  0.040295          0        100  ...        4.8         5.6   \n",
              "2     0.034352  0.040295          0        100  ...        4.8         5.6   \n",
              "3     0.000000  0.269410          0        100  ...        5.1         5.6   \n",
              "4     0.000000  0.379107          0        100  ...        5.0         5.2   \n",
              "..         ...       ...        ...        ...  ...        ...         ...   \n",
              "249  15.116930  0.698221          0          0  ...        4.6         4.3   \n",
              "250   0.000000  1.725019          0          0  ...        4.6         4.1   \n",
              "251  15.054404  0.991284          0          0  ...        4.5         4.3   \n",
              "252   4.306276  0.000000          0          0  ...        4.6         4.0   \n",
              "253   6.042903  0.595441          0          0  ...        4.7         4.4   \n",
              "\n",
              "     Vent_Mai  Vent_Juin  Vent_Juill  Vent_Aout  Vent_Sept  Vent_Oct  \\\n",
              "0         7.2        7.1         7.5        7.2        6.3       5.4   \n",
              "1         5.7        6.4         5.9        5.9        5.7       4.3   \n",
              "2         5.7        6.4         5.9        5.9        5.7       4.3   \n",
              "3         5.5        6.2         6.2        6.2        5.7       4.1   \n",
              "4         5.4        5.7         6.2        5.8        5.6       4.2   \n",
              "..        ...        ...         ...        ...        ...       ...   \n",
              "249       4.1        3.9         3.9        4.1        4.0       4.0   \n",
              "250       3.8        3.7         3.7        3.7        3.3       3.6   \n",
              "251       4.0        4.0         3.9        4.0        3.9       4.0   \n",
              "252       3.8        4.1         3.7        3.4        3.6       3.6   \n",
              "253       3.9        3.8         3.9        3.7        4.0       4.0   \n",
              "\n",
              "     Vent_Nov  Vent_Dec  \n",
              "0         5.5       4.9  \n",
              "1         3.7       3.8  \n",
              "2         3.7       3.8  \n",
              "3         3.7       3.9  \n",
              "4         3.6       3.8  \n",
              "..        ...       ...  \n",
              "249       4.0       4.2  \n",
              "250       3.8       4.0  \n",
              "251       3.9       4.3  \n",
              "252       3.4       3.6  \n",
              "253       4.0       4.2  \n",
              "\n",
              "[254 rows x 226 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08263f2e-240f-4e5a-8fe8-07cfa99a8566\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X_long</th>\n",
              "      <th>Y_lat</th>\n",
              "      <th>Cs_longia</th>\n",
              "      <th>Bovins</th>\n",
              "      <th>Volaille</th>\n",
              "      <th>Caprins</th>\n",
              "      <th>Ovins</th>\n",
              "      <th>Equides</th>\n",
              "      <th>Coniferes</th>\n",
              "      <th>ZoneAride</th>\n",
              "      <th>...</th>\n",
              "      <th>Vent_Mars</th>\n",
              "      <th>Vent_Avril</th>\n",
              "      <th>Vent_Mai</th>\n",
              "      <th>Vent_Juin</th>\n",
              "      <th>Vent_Juill</th>\n",
              "      <th>Vent_Aout</th>\n",
              "      <th>Vent_Sept</th>\n",
              "      <th>Vent_Oct</th>\n",
              "      <th>Vent_Nov</th>\n",
              "      <th>Vent_Dec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-15.911420</td>\n",
              "      <td>23.794740</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.624435</td>\n",
              "      <td>0</td>\n",
              "      <td>97</td>\n",
              "      <td>...</td>\n",
              "      <td>6.1</td>\n",
              "      <td>6.9</td>\n",
              "      <td>7.2</td>\n",
              "      <td>7.1</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>5.4</td>\n",
              "      <td>5.5</td>\n",
              "      <td>4.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-13.188370</td>\n",
              "      <td>27.132950</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.063449</td>\n",
              "      <td>0.034352</td>\n",
              "      <td>0.040295</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>5.7</td>\n",
              "      <td>6.4</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.7</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-13.188370</td>\n",
              "      <td>27.132950</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.063449</td>\n",
              "      <td>0.034352</td>\n",
              "      <td>0.040295</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>5.7</td>\n",
              "      <td>6.4</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.7</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-13.185620</td>\n",
              "      <td>27.157940</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269410</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>5.1</td>\n",
              "      <td>5.6</td>\n",
              "      <td>5.5</td>\n",
              "      <td>6.2</td>\n",
              "      <td>6.2</td>\n",
              "      <td>6.2</td>\n",
              "      <td>5.7</td>\n",
              "      <td>4.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-13.167180</td>\n",
              "      <td>27.157730</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.379107</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>5.4</td>\n",
              "      <td>5.7</td>\n",
              "      <td>6.2</td>\n",
              "      <td>5.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>-5.366667</td>\n",
              "      <td>35.766667</td>\n",
              "      <td>1</td>\n",
              "      <td>8.495770</td>\n",
              "      <td>105.550156</td>\n",
              "      <td>8.691405</td>\n",
              "      <td>15.116930</td>\n",
              "      <td>0.698221</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>-5.816667</td>\n",
              "      <td>35.783333</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.725019</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.3</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>-5.366667</td>\n",
              "      <td>35.833333</td>\n",
              "      <td>1</td>\n",
              "      <td>7.411978</td>\n",
              "      <td>111.459663</td>\n",
              "      <td>7.364459</td>\n",
              "      <td>15.054404</td>\n",
              "      <td>0.991284</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>-5.558611</td>\n",
              "      <td>35.841944</td>\n",
              "      <td>1</td>\n",
              "      <td>5.696193</td>\n",
              "      <td>5.641273</td>\n",
              "      <td>0.602672</td>\n",
              "      <td>4.306276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>-5.483333</td>\n",
              "      <td>35.900000</td>\n",
              "      <td>1</td>\n",
              "      <td>6.839514</td>\n",
              "      <td>15.082421</td>\n",
              "      <td>0.782080</td>\n",
              "      <td>6.042903</td>\n",
              "      <td>0.595441</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254 rows × 226 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08263f2e-240f-4e5a-8fe8-07cfa99a8566')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08263f2e-240f-4e5a-8fe8-07cfa99a8566 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08263f2e-240f-4e5a-8fe8-07cfa99a8566');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "del data[\"Source\"] \n",
        "del data[\"CodeSite\"] \n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Cs_longia\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwvIdiHDHxV2",
        "outputId": "adc57a5a-aab5-46f4-e118-a2a79581a565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "249    1\n",
              "250    1\n",
              "251    1\n",
              "252    1\n",
              "253    1\n",
              "Name: Cs_longia, Length: 254, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlXmEfpym-Hm"
      },
      "outputs": [],
      "source": [
        "X = data.loc[:, data.columns != 'Cs_longia']\n",
        "y = data.Cs_longia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "jKMLLkKq1r3N",
        "outputId": "59f6675b-7829-4a74-cb0c-99553df64144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        X_long      Y_lat    Bovins    Volaille   Caprins      Ovins  \\\n",
              "0   -15.911420  23.794740  0.000000    0.000000  0.000000   0.000000   \n",
              "1   -13.188370  27.132950  0.000214    0.000000  0.063449   0.034352   \n",
              "2   -13.188370  27.132950  0.000214    0.000000  0.063449   0.034352   \n",
              "3   -13.185620  27.157940  0.000000    0.000000  0.000000   0.000000   \n",
              "4   -13.167180  27.157730  0.000000    0.000000  0.000000   0.000000   \n",
              "..         ...        ...       ...         ...       ...        ...   \n",
              "249  -5.366667  35.766667  8.495770  105.550156  8.691405  15.116930   \n",
              "250  -5.816667  35.783333  0.000000    0.000000  0.000000   0.000000   \n",
              "251  -5.366667  35.833333  7.411978  111.459663  7.364459  15.054404   \n",
              "252  -5.558611  35.841944  5.696193    5.641273  0.602672   4.306276   \n",
              "253  -5.483333  35.900000  6.839514   15.082421  0.782080   6.042903   \n",
              "\n",
              "      Equides  Coniferes  ZoneAride  ZonePel  ...  Vent_Mars  Vent_Avril  \\\n",
              "0    0.624435          0         97        3  ...        6.1         6.9   \n",
              "1    0.040295          0        100        0  ...        4.8         5.6   \n",
              "2    0.040295          0        100        0  ...        4.8         5.6   \n",
              "3    0.269410          0        100        0  ...        5.1         5.6   \n",
              "4    0.379107          0        100        0  ...        5.0         5.2   \n",
              "..        ...        ...        ...      ...  ...        ...         ...   \n",
              "249  0.698221          0          0        0  ...        4.6         4.3   \n",
              "250  1.725019          0          0        0  ...        4.6         4.1   \n",
              "251  0.991284          0          0        0  ...        4.5         4.3   \n",
              "252  0.000000          0          0       58  ...        4.6         4.0   \n",
              "253  0.595441          0          0        5  ...        4.7         4.4   \n",
              "\n",
              "     Vent_Mai  Vent_Juin  Vent_Juill  Vent_Aout  Vent_Sept  Vent_Oct  \\\n",
              "0         7.2        7.1         7.5        7.2        6.3       5.4   \n",
              "1         5.7        6.4         5.9        5.9        5.7       4.3   \n",
              "2         5.7        6.4         5.9        5.9        5.7       4.3   \n",
              "3         5.5        6.2         6.2        6.2        5.7       4.1   \n",
              "4         5.4        5.7         6.2        5.8        5.6       4.2   \n",
              "..        ...        ...         ...        ...        ...       ...   \n",
              "249       4.1        3.9         3.9        4.1        4.0       4.0   \n",
              "250       3.8        3.7         3.7        3.7        3.3       3.6   \n",
              "251       4.0        4.0         3.9        4.0        3.9       4.0   \n",
              "252       3.8        4.1         3.7        3.4        3.6       3.6   \n",
              "253       3.9        3.8         3.9        3.7        4.0       4.0   \n",
              "\n",
              "     Vent_Nov  Vent_Dec  \n",
              "0         5.5       4.9  \n",
              "1         3.7       3.8  \n",
              "2         3.7       3.8  \n",
              "3         3.7       3.9  \n",
              "4         3.6       3.8  \n",
              "..        ...       ...  \n",
              "249       4.0       4.2  \n",
              "250       3.8       4.0  \n",
              "251       3.9       4.3  \n",
              "252       3.4       3.6  \n",
              "253       4.0       4.2  \n",
              "\n",
              "[254 rows x 225 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-482d71e5-b18a-4681-95a1-8f1e18bc1f82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X_long</th>\n",
              "      <th>Y_lat</th>\n",
              "      <th>Bovins</th>\n",
              "      <th>Volaille</th>\n",
              "      <th>Caprins</th>\n",
              "      <th>Ovins</th>\n",
              "      <th>Equides</th>\n",
              "      <th>Coniferes</th>\n",
              "      <th>ZoneAride</th>\n",
              "      <th>ZonePel</th>\n",
              "      <th>...</th>\n",
              "      <th>Vent_Mars</th>\n",
              "      <th>Vent_Avril</th>\n",
              "      <th>Vent_Mai</th>\n",
              "      <th>Vent_Juin</th>\n",
              "      <th>Vent_Juill</th>\n",
              "      <th>Vent_Aout</th>\n",
              "      <th>Vent_Sept</th>\n",
              "      <th>Vent_Oct</th>\n",
              "      <th>Vent_Nov</th>\n",
              "      <th>Vent_Dec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-15.911420</td>\n",
              "      <td>23.794740</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.624435</td>\n",
              "      <td>0</td>\n",
              "      <td>97</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>6.1</td>\n",
              "      <td>6.9</td>\n",
              "      <td>7.2</td>\n",
              "      <td>7.1</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>5.4</td>\n",
              "      <td>5.5</td>\n",
              "      <td>4.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-13.188370</td>\n",
              "      <td>27.132950</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.063449</td>\n",
              "      <td>0.034352</td>\n",
              "      <td>0.040295</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>5.7</td>\n",
              "      <td>6.4</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.7</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-13.188370</td>\n",
              "      <td>27.132950</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.063449</td>\n",
              "      <td>0.034352</td>\n",
              "      <td>0.040295</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>5.7</td>\n",
              "      <td>6.4</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.7</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-13.185620</td>\n",
              "      <td>27.157940</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269410</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.1</td>\n",
              "      <td>5.6</td>\n",
              "      <td>5.5</td>\n",
              "      <td>6.2</td>\n",
              "      <td>6.2</td>\n",
              "      <td>6.2</td>\n",
              "      <td>5.7</td>\n",
              "      <td>4.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-13.167180</td>\n",
              "      <td>27.157730</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.379107</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>5.4</td>\n",
              "      <td>5.7</td>\n",
              "      <td>6.2</td>\n",
              "      <td>5.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>-5.366667</td>\n",
              "      <td>35.766667</td>\n",
              "      <td>8.495770</td>\n",
              "      <td>105.550156</td>\n",
              "      <td>8.691405</td>\n",
              "      <td>15.116930</td>\n",
              "      <td>0.698221</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>-5.816667</td>\n",
              "      <td>35.783333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.725019</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.3</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>-5.366667</td>\n",
              "      <td>35.833333</td>\n",
              "      <td>7.411978</td>\n",
              "      <td>111.459663</td>\n",
              "      <td>7.364459</td>\n",
              "      <td>15.054404</td>\n",
              "      <td>0.991284</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>-5.558611</td>\n",
              "      <td>35.841944</td>\n",
              "      <td>5.696193</td>\n",
              "      <td>5.641273</td>\n",
              "      <td>0.602672</td>\n",
              "      <td>4.306276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>...</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>-5.483333</td>\n",
              "      <td>35.900000</td>\n",
              "      <td>6.839514</td>\n",
              "      <td>15.082421</td>\n",
              "      <td>0.782080</td>\n",
              "      <td>6.042903</td>\n",
              "      <td>0.595441</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>4.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254 rows × 225 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-482d71e5-b18a-4681-95a1-8f1e18bc1f82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-482d71e5-b18a-4681-95a1-8f1e18bc1f82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-482d71e5-b18a-4681-95a1-8f1e18bc1f82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "algo = GradientBoostingClassifier(n_estimators=225, learning_rate=0.1, max_features=1, max_depth=2, random_state=0,min_samples_leaf=2,subsample=1 )"
      ],
      "metadata": {
        "id": "Nms5zJVW_Jcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo1 = GradientBoostingClassifier(n_estimators=225, learning_rate=0.1, random_state=0)"
      ],
      "metadata": {
        "id": "LYx5LQPsC4nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clmns=X.columns"
      ],
      "metadata": {
        "id": "LO6kTQML0JfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clmns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gn7BsFo0Lbd",
        "outputId": "372a36d3-24bb-4762-94a1-e0a75ffc7aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['X_long', 'Y_lat', 'Bovins', 'Volaille', 'Caprins', 'Ovins', 'Equides',\n",
              "       'Coniferes', 'ZoneAride', 'ZonePel',\n",
              "       ...\n",
              "       'Vent_Mars', 'Vent_Avril', 'Vent_Mai', 'Vent_Juin', 'Vent_Juill',\n",
              "       'Vent_Aout', 'Vent_Sept', 'Vent_Oct', 'Vent_Nov', 'Vent_Dec'],\n",
              "      dtype='object', length=225)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(X, fs) :\n",
        "  X_ = X.copy()\n",
        "  for i in range(len(fs)) :\n",
        "    if fs[i] == False :\n",
        "      X_.drop([clmns[i]], axis=1, inplace=True)\n",
        "  return X_"
      ],
      "metadata": {
        "id": "R5zttnyxbB1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Retransform (lst):\n",
        "  Fs=[]      \n",
        "  for i in range(225):\n",
        "    if clmns[i] in lst :\n",
        "       Fs.append(True)\n",
        "    else :\n",
        "       Fs.append(False)\n",
        "  return Fs\n",
        "\n"
      ],
      "metadata": {
        "id": "himmHRlOPPNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst= ['Min_IRM', 'Amp1_TempJ', 'Max_TempN', 'VarT_ann_NDVI', 'Var_EVI',\n",
        "       'ProfAbs_Sub', 'IR_Moy', 'Rad_Mai', 'Tmax_Fev', 'Tmax_Avril']"
      ],
      "metadata": {
        "id": "vftB4quk0p5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fs = Retransform (lst)"
      ],
      "metadata": {
        "id": "tNKeoyD1Paw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O2GIknOP7-x",
        "outputId": "4ecb75d2-b572-4e0b-c481-c811b4275d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MCC(y_true, y_pred):\n",
        "  MCC= matthews_corrcoef(y_true, y_pred) \n",
        "  return MCC\n",
        "score1 = make_scorer(MCC, greater_is_better=True)"
      ],
      "metadata": {
        "id": "b7Jk32FkKiW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqv89fz_9Zr9"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "explored_models = []\n",
        "scores = []\n",
        "def explor(fs, acc, algo) :\n",
        "  if (sum(fs) < 5 or sum(fs) > 225) :\n",
        "    return\n",
        "  explored_models.append(fs)\n",
        "  for i in range(225) :\n",
        "    neighbor = fs.copy()\n",
        "    neighbor[i] = not fs[i]\n",
        "    if (neighbor not in explored_models) :\n",
        "      score = cross_val_score(algo, transform(X, neighbor) , y, scoring=score1, cv=cv, n_jobs=-1)\n",
        "      mean_score = np.mean(score)\n",
        "      if mean_score  >= acc :\n",
        "        print(mean_score)\n",
        "        scores.append(mean_score)\n",
        "        explor(neighbor, mean_score, algo)\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explor(Fs, 0.51, algo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "beIogGBvzowP",
        "outputId": "d48ba2a2-3290-4ea2-c871-28d5777e1946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5350642316043925\n",
            "0.5388595213609009\n",
            "0.5387044660494723\n",
            "0.5394085318816341\n",
            "0.5524520395195636\n",
            "0.5454211218351309\n",
            "0.5510063052206171\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-b239fd63d5b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexplor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.51\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-87-e8724c124dcf>\u001b[0m in \u001b[0;36mexplor\u001b[0;34m(fs, acc, algo)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mexplor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-e8724c124dcf>\u001b[0m in \u001b[0;36mexplor\u001b[0;34m(fs, acc, algo)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mexplor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-e8724c124dcf>\u001b[0m in \u001b[0;36mexplor\u001b[0;34m(fs, acc, algo)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mexplor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-e8724c124dcf>\u001b[0m in \u001b[0;36mexplor\u001b[0;34m(fs, acc, algo)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mexplor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-e8724c124dcf>\u001b[0m in \u001b[0;36mexplor\u001b[0;34m(fs, acc, algo)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mneighbor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mneighbor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexplored_models\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mmean_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmean_score\u001b[0m  \u001b[0;34m>=\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snwGDGrOCHIy",
        "outputId": "5d4c99f3-9215-430f-e7cd-ccf60eb4df07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5350642316043925,\n",
              " 0.5388595213609009,\n",
              " 0.5387044660494723,\n",
              " 0.5394085318816341,\n",
              " 0.5524520395195636,\n",
              " 0.5454211218351309,\n",
              " 0.5510063052206171]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explored_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWdin29cAICu",
        "outputId": "381cc0bd-b8d9-4c5c-a2f4-44173d262492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False],\n",
              " [False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False],\n",
              " [False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False],\n",
              " [False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False],\n",
              " [False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  True,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False],\n",
              " [False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  True,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False],\n",
              " [False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  True,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False],\n",
              " [False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  True,\n",
              "  True,\n",
              "  True,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False,\n",
              "  False]]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_acc = 0\n",
        "pos = 0\n",
        "for i in range(len(scores)) :\n",
        "  if scores[i] > max_acc :\n",
        "    max_acc = scores[i]\n",
        "    pos = i\n",
        "print(max_acc, pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NICxZlAJZ0YP",
        "outputId": "17b27e67-b906-4e14-a95e-707ae3b8bd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5524520395195636 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "scores1 = cross_val_score(algo, transform(X, RR), y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "scores2 = cross_val_score(algo, transform(X, RR), y, scoring='recall', cv=cv, n_jobs=-1)\n",
        "scores3 = cross_val_score(algo, transform(X, RR), y, scoring=my_scorer, cv=cv, n_jobs=-1)\n",
        "scores4 = cross_val_score(algo, transform(X, RR), y, scoring=my_scorer1, cv=cv, n_jobs=-1)\n",
        "scores5 = cross_val_score(algo, transform(X, RR), y, scoring=my_scorer2, cv=cv, n_jobs=-1)\n",
        "scores6 = cross_val_score(algo, transform(X, RR), y, scoring=my_scorer3, cv=cv, n_jobs=-1)\n",
        "scores7 = cross_val_score(algo, transform(X, RR), y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "scores8 = cross_val_score(algo, transform(X, RR), y, scoring=my_scorer4, cv=cv, n_jobs=-1)\n",
        "scores9 = cross_val_score(algo, transform(X, RR), y, scoring=my_scorer5, cv=cv, n_jobs=-1)\n",
        "scores10 = cross_val_score(algo, transform(X, RR), y, scoring=my_scorer6, cv=cv, n_jobs=-1)\n",
        "scores11 = cross_val_score(algo, transform(X, RR), y, scoring=my_scorer7, cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy:',scores1)\n",
        "print('moy_accuracy: %.2f' % mean(scores1))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('sensibilité :',scores2)\n",
        "print('moy_sensibilité: %.2f' % mean(scores2))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('spécificité :',scores3)\n",
        "print('moy_spécificité: %.2f' % mean(scores3))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('MCC :',scores4)\n",
        "print('MCC: %.2f' % mean(scores4))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('precision-po:',scores5)\n",
        "print('moy_precision-po: %.2f' % mean(scores5))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('precision-ne :',scores6)\n",
        "print('moy_precision-ne: %.2f' % mean(scores6))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('AUC :',scores7)\n",
        "print('moy_AUC: %.2f' % mean(scores7))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('VN :',scores8)\n",
        "print('VP :',scores9)\n",
        "print('FP :',scores10)\n",
        "print('FN :',scores11)\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\"-------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c64dce5-583a-421d-f169-34118b166fb8",
        "id": "I6vpTbgNiQQu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: [0.76470588 0.70588235 0.78431373 0.76470588 0.7       ]\n",
            "moy_accuracy: 0.74\n",
            "-------------------------------------------------\n",
            "sensibilité : [0.70967742 0.72727273 0.7        0.75       0.75      ]\n",
            "moy_sensibilité: 0.73\n",
            "-------------------------------------------------\n",
            "spécificité : [0.85       0.68965517 0.9047619  0.77419355 0.65384615]\n",
            "moy_spécificité: 0.77\n",
            "-------------------------------------------------\n",
            "MCC : [0.54660922 0.41306141 0.59815229 0.51674606 0.40482045]\n",
            "MCC: 0.50\n",
            "-------------------------------------------------\n",
            "precision-po: [0.88       0.64       0.91304348 0.68181818 0.66666667]\n",
            "moy_precision-po: 0.76\n",
            "-------------------------------------------------\n",
            "precision-ne : [0.65384615 0.76923077 0.67857143 0.82758621 0.73913043]\n",
            "moy_precision-ne: 0.73\n",
            "-------------------------------------------------\n",
            "AUC : [0.81854839 0.80329154 0.8        0.8516129  0.76762821]\n",
            "moy_AUC: 0.81\n",
            "-------------------------------------------------\n",
            "VN : [17 20 19 24 17]\n",
            "VP : [22 16 21 15 18]\n",
            "FP : [3 9 2 7 9]\n",
            "FN : [9 6 9 5 6]\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def specificite(y_true, y_pred):\n",
        "  specificite= confusion_matrix(y_true, y_pred)[0,0]/(confusion_matrix(y_true,y_pred)[0,0] + confusion_matrix(y_true, y_pred)[0,1])\n",
        "  return specificite\n",
        "my_scorer = make_scorer(specificite, greater_is_better=True)\n",
        "def MCC(y_true, y_pred):\n",
        "  MCC= matthews_corrcoef(y_true, y_pred) \n",
        "  return MCC\n",
        "my_scorer1 = make_scorer(MCC, greater_is_better=True)\n",
        "def présicion_positive(y_val, preds):\n",
        "  cf_matrix = confusion_matrix(y_val, preds)\n",
        "  pre_pos =  (cf_matrix[1,1])/(cf_matrix[1,1]+cf_matrix[0,1])\n",
        "  return pre_pos\n",
        "my_scorer2 = make_scorer(présicion_positive, greater_is_better=True)\n",
        "def présicion_négative(y_val, preds):\n",
        "  cf_matrix = confusion_matrix(y_val, preds)\n",
        "  pre_pos =  (cf_matrix[0,0])/(cf_matrix[0,0]+cf_matrix[1,0])\n",
        "  return pre_pos\n",
        "my_scorer3 = make_scorer(présicion_négative, greater_is_better=True)\n",
        "def VN(y_true, y_pred):\n",
        "    value = confusion_matrix(y_true, y_pred)[0,0]\n",
        "    return value\n",
        "my_scorer4 = make_scorer(VN, greater_is_better=True)\n",
        "def VP(y_true, y_pred):\n",
        "    value = confusion_matrix(y_true, y_pred)[1,1]\n",
        "    return value\n",
        "my_scorer5 = make_scorer(VP, greater_is_better=True)\n",
        "def FP(y_true, y_pred):\n",
        "    value = confusion_matrix(y_true, y_pred)[0,1]\n",
        "    return value\n",
        "my_scorer6 = make_scorer(FP, greater_is_better=True)\n",
        "def FN(y_true, y_pred):\n",
        "    value = confusion_matrix(y_true, y_pred)[1,0]\n",
        "    return value\n",
        "my_scorer7 = make_scorer(FN, greater_is_better=True)"
      ],
      "metadata": {
        "id": "8kHoQLziaAgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "scores1 = cross_val_score(algo, transform(X, best_so_far), y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "scores2 = cross_val_score(algo, transform(X, best_so_far), y, scoring='recall', cv=cv, n_jobs=-1)\n",
        "scores3 = cross_val_score(algo, transform(X, best_so_far), y, scoring=my_scorer, cv=cv, n_jobs=-1)\n",
        "scores4 = cross_val_score(algo, transform(X, best_so_far), y, scoring=my_scorer1, cv=cv, n_jobs=-1)\n",
        "scores5 = cross_val_score(algo, transform(X, best_so_far), y, scoring=my_scorer2, cv=cv, n_jobs=-1)\n",
        "scores6 = cross_val_score(algo, transform(X, best_so_far), y, scoring=my_scorer3, cv=cv, n_jobs=-1)\n",
        "scores7 = cross_val_score(algo, transform(X, best_so_far), y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "scores8 = cross_val_score(algo, transform(X, best_so_far), y, scoring=my_scorer4, cv=cv, n_jobs=-1)\n",
        "scores9 = cross_val_score(algo, transform(X, best_so_far), y, scoring=my_scorer5, cv=cv, n_jobs=-1)\n",
        "scores10 = cross_val_score(algo, transform(X, best_so_far), y, scoring=my_scorer6, cv=cv, n_jobs=-1)\n",
        "scores11 = cross_val_score(algo, transform(X, best_so_far), y, scoring=my_scorer7, cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy:',scores1)\n",
        "print('moy_accuracy: %.2f' % mean(scores1))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('sensibilité :',scores2)\n",
        "print('moy_sensibilité: %.2f' % mean(scores2))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('spécificité :',scores3)\n",
        "print('moy_spécificité: %.2f' % mean(scores3))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('MCC :',scores4)\n",
        "print('MCC: %.2f' % mean(scores4))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('precision-po:',scores5)\n",
        "print('moy_precision-po: %.2f' % mean(scores5))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('precision-ne :',scores6)\n",
        "print('moy_precision-ne: %.2f' % mean(scores6))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('AUC :',scores7)\n",
        "print('moy_AUC: %.2f' % mean(scores7))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('VN :',scores8)\n",
        "print('VP :',scores9)\n",
        "print('FP :',scores10)\n",
        "print('FN :',scores11)\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\"-------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRt3RvCnaHRf",
        "outputId": "eee06053-5a9c-44b4-8f32-f658e8d64f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: [0.7254902  0.78431373 0.78431373 0.78431373 0.74      ]\n",
            "moy_accuracy: 0.76\n",
            "-------------------------------------------------\n",
            "sensibilité : [0.61290323 0.72727273 0.73333333 0.8        0.79166667]\n",
            "moy_sensibilité: 0.73\n",
            "-------------------------------------------------\n",
            "spécificité : [0.9        0.82758621 0.85714286 0.77419355 0.69230769]\n",
            "moy_spécificité: 0.81\n",
            "-------------------------------------------------\n",
            "MCC : [0.50881628 0.55837073 0.58132097 0.56339271 0.48514197]\n",
            "MCC: 0.54\n",
            "-------------------------------------------------\n",
            "precision-po: [0.9047619  0.76190476 0.88       0.69565217 0.7037037 ]\n",
            "moy_precision-po: 0.79\n",
            "-------------------------------------------------\n",
            "precision-ne : [0.6        0.8        0.69230769 0.85714286 0.7826087 ]\n",
            "moy_precision-ne: 0.75\n",
            "-------------------------------------------------\n",
            "AUC : [0.80080645 0.78134796 0.81746032 0.83064516 0.75801282]\n",
            "moy_AUC: 0.80\n",
            "-------------------------------------------------\n",
            "VN : [18 24 18 24 18]\n",
            "VP : [19 16 22 16 19]\n",
            "FP : [2 5 3 7 8]\n",
            "FN : [12  6  8  4  5]\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform(X, best_so_far)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8WS5LIO8awkF",
        "outputId": "c2d9f631-bc2b-4aa0-d5d2-32779316a777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Min_IRM  Amp1_TempJ  Max_TempN  VarT_ann_NDVI  Var_EVI     IR_Moy  \\\n",
              "0       2690          96      14561              2        1   1.968750   \n",
              "1       3350         312      14705             13        0   1.375000   \n",
              "2       3350         312      14705             13        0   1.375000   \n",
              "3       2930         306      14690              8        0   9.304688   \n",
              "4       2350         295      14719              1       35   7.515625   \n",
              "..       ...         ...        ...            ...      ...        ...   \n",
              "249      880         543      14675             52       47  25.093750   \n",
              "250     1400         478      14743             51        7   6.578125   \n",
              "251     1080         452      14666             84       70  15.914062   \n",
              "252      620           0          0             37       40  14.812500   \n",
              "253      990         366      14647             77       39  30.250000   \n",
              "\n",
              "     Rad_Mai   Tmax_Fev  Tmax_Mars  Tmax_Avril  \n",
              "0      24920  21.799999  22.700001   22.600000  \n",
              "1      24082  22.600000  24.000000   24.600000  \n",
              "2      24082  22.600000  24.000000   24.600000  \n",
              "3      24019  22.600000  24.000000   24.600000  \n",
              "4      24002  22.799999  24.100000   24.700001  \n",
              "..       ...        ...        ...         ...  \n",
              "249    23341  15.400000  17.299999   18.900000  \n",
              "250    23582  15.500000  17.299999   18.700001  \n",
              "251    23425  15.500000  17.400000   18.900000  \n",
              "252    23716  17.100000  18.500000   19.799999  \n",
              "253    23699  16.299999  17.700001   19.000000  \n",
              "\n",
              "[254 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c38049ba-b50d-4cee-812e-b54db069bfb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Min_IRM</th>\n",
              "      <th>Amp1_TempJ</th>\n",
              "      <th>Max_TempN</th>\n",
              "      <th>VarT_ann_NDVI</th>\n",
              "      <th>Var_EVI</th>\n",
              "      <th>IR_Moy</th>\n",
              "      <th>Rad_Mai</th>\n",
              "      <th>Tmax_Fev</th>\n",
              "      <th>Tmax_Mars</th>\n",
              "      <th>Tmax_Avril</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2690</td>\n",
              "      <td>96</td>\n",
              "      <td>14561</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.968750</td>\n",
              "      <td>24920</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>22.700001</td>\n",
              "      <td>22.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3350</td>\n",
              "      <td>312</td>\n",
              "      <td>14705</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>24082</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>24.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3350</td>\n",
              "      <td>312</td>\n",
              "      <td>14705</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>24082</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>24.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2930</td>\n",
              "      <td>306</td>\n",
              "      <td>14690</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>9.304688</td>\n",
              "      <td>24019</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>24.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2350</td>\n",
              "      <td>295</td>\n",
              "      <td>14719</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>7.515625</td>\n",
              "      <td>24002</td>\n",
              "      <td>22.799999</td>\n",
              "      <td>24.100000</td>\n",
              "      <td>24.700001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>880</td>\n",
              "      <td>543</td>\n",
              "      <td>14675</td>\n",
              "      <td>52</td>\n",
              "      <td>47</td>\n",
              "      <td>25.093750</td>\n",
              "      <td>23341</td>\n",
              "      <td>15.400000</td>\n",
              "      <td>17.299999</td>\n",
              "      <td>18.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>1400</td>\n",
              "      <td>478</td>\n",
              "      <td>14743</td>\n",
              "      <td>51</td>\n",
              "      <td>7</td>\n",
              "      <td>6.578125</td>\n",
              "      <td>23582</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>17.299999</td>\n",
              "      <td>18.700001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>1080</td>\n",
              "      <td>452</td>\n",
              "      <td>14666</td>\n",
              "      <td>84</td>\n",
              "      <td>70</td>\n",
              "      <td>15.914062</td>\n",
              "      <td>23425</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>17.400000</td>\n",
              "      <td>18.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>620</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>40</td>\n",
              "      <td>14.812500</td>\n",
              "      <td>23716</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>19.799999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>990</td>\n",
              "      <td>366</td>\n",
              "      <td>14647</td>\n",
              "      <td>77</td>\n",
              "      <td>39</td>\n",
              "      <td>30.250000</td>\n",
              "      <td>23699</td>\n",
              "      <td>16.299999</td>\n",
              "      <td>17.700001</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c38049ba-b50d-4cee-812e-b54db069bfb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c38049ba-b50d-4cee-812e-b54db069bfb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c38049ba-b50d-4cee-812e-b54db069bfb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###################################"
      ],
      "metadata": {
        "id": "gWVc5p4JyqgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "explored_models2 = []\n",
        "scores_sensibilite = []\n",
        "scores_specificite = []\n",
        "models_mm2=[]\n",
        "def explor2(fs, sen, spe, algo) :\n",
        "  if (sum(fs) < 5 or sum(fs) > 225) :\n",
        "    return\n",
        "  explored_models2.append(fs)\n",
        "  for i in range(225) :\n",
        "    neighbor = fs.copy()\n",
        "    neighbor[i] = not fs[i]\n",
        "    if (neighbor not in explored_models2) :\n",
        "      score_sensibilite = cross_val_score(algo, transform(X, neighbor) , y, scoring='recall', cv=cv, n_jobs=-1)\n",
        "      score_specificite = cross_val_score(algo, transform(X, neighbor) , y, scoring=my_scorer, cv=cv, n_jobs=-1)\n",
        "      mean_score_sensibilite = np.mean(score_sensibilite)\n",
        "      mean_score_specificite = np.mean(score_specificite)\n",
        "      if (mean_score_sensibilite  >= sen  and  mean_score_specificite >= spe) :\n",
        "        models_mm2.append(neighbor)\n",
        "        print(\"sensibilite\", mean_score_sensibilite)\n",
        "        print(\"specificite\", mean_score_specificite)\n",
        "        print(\"-----------\")\n",
        "        scores_sensibilite.append(mean_score_sensibilite)\n",
        "        scores_specificite.append(mean_score_specificite)\n",
        "        explor2(neighbor, mean_score_sensibilite,mean_score_specificite, algo)"
      ],
      "metadata": {
        "id": "wK42kdEOQbuh"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fs"
      ],
      "metadata": {
        "id": "8mMLFG0LWwHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform(X,Fs)"
      ],
      "metadata": {
        "id": "rfd5h2l4mUL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explor2(Fs, 0.73,0.78, algo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "mCSo-aaTWXae",
        "outputId": "07e6f66f-c5f4-4da0-aecc-c505b74c3c13"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sensibilite 0.7500293255131966\n",
            "specificite 0.8035389749294088\n",
            "-----------\n",
            "sensibilite 0.7516959921798632\n",
            "specificite 0.8070125128857054\n",
            "-----------\n",
            "sensibilite 0.7524535679374389\n",
            "specificite 0.8211876851365172\n",
            "-----------\n",
            "sensibilite 0.7681476050830889\n",
            "specificite 0.8231928842384905\n",
            "-----------\n",
            "sensibilite 0.763147605083089\n",
            "specificite 0.8067725229905431\n",
            "-----------\n",
            "sensibilite 0.7786901270772238\n",
            "specificite 0.8091790634282292\n",
            "-----------\n",
            "sensibilite 0.773147605083089\n",
            "specificite 0.8275370273034344\n",
            "-----------\n",
            "sensibilite 0.773147605083089\n",
            "specificite 0.8326020771960705\n",
            "-----------\n",
            "sensibilite 0.7593352883675465\n",
            "specificite 0.813464125788931\n",
            "-----------\n",
            "sensibilite 0.7598142717497556\n",
            "specificite 0.8250243860699923\n",
            "-----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-4955314f2904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexplor2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.73\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.78\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-102-01bc4d958e72>\u001b[0m in \u001b[0;36mexplor2\u001b[0;34m(fs, sen, spe, algo)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mneighbor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexplored_models2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mscore_sensibilite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mscore_specificite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_scorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mmean_score_sensibilite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_sensibilite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mmean_score_specificite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_specificite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-5173102bc845>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(X, fs)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclmns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6011\u001b[0m         \u001b[0marr_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"object\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"object\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6012\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_labels_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marr_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6013\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6014\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer_for\u001b[0;34m(self, target, **kwargs)\u001b[0m\n\u001b[1;32m   5273\u001b[0m         \"\"\"\n\u001b[1;32m   5274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5276\u001b[0m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3435\u001b[0m         \u001b[0;31m# returned ndarray is np.intp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3436\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_reindex_fill_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3437\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_maybe_cast_listlike_indexer\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   5706\u001b[0m         \u001b[0mAnalogue\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmaybe_cast_indexer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mget_indexer\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5707\u001b[0m         \"\"\"\n\u001b[0;32m-> 5708\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5710\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   6334\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_to_subclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0mdisallow_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_ensure_array\u001b[0;34m(cls, data, dtype, copy)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mEnsure\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mhave\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0marray\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mpass\u001b[0m \u001b[0mto\u001b[0m \u001b[0m_simple_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;31m# GH#13601, GH#20285, GH#27125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(explored_models2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-ejkrNphPbY",
        "outputId": "e1872ae8-8327-4f6c-dfaa-5977606e93c2"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_specificite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jAtTNLJ6WXP",
        "outputId": "9b4dce85-bd1b-4880-be3c-cfc29e002a26"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.792948167886989,\n",
              " 0.794220114331349,\n",
              " 0.8003209100873173,\n",
              " 0.8035389749294088,\n",
              " 0.8070125128857054,\n",
              " 0.8211876851365172,\n",
              " 0.8231928842384905,\n",
              " 0.8067725229905431,\n",
              " 0.8091790634282292,\n",
              " 0.8275370273034344,\n",
              " 0.8326020771960705,\n",
              " 0.813464125788931,\n",
              " 0.8250243860699923]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_sensibilite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4HJlNaN6H06",
        "outputId": "2e56647e-5a7d-4e03-a1b9-2f9df3647390"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7309384164222873,\n",
              " 0.7361534701857282,\n",
              " 0.75405669599218,\n",
              " 0.7500293255131966,\n",
              " 0.7516959921798632,\n",
              " 0.7524535679374389,\n",
              " 0.7681476050830889,\n",
              " 0.763147605083089,\n",
              " 0.7786901270772238,\n",
              " 0.773147605083089,\n",
              " 0.773147605083089,\n",
              " 0.7593352883675465,\n",
              " 0.7598142717497556]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(models_mm2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH7hhSkwjeLZ",
        "outputId": "35f4dee4-f110-4c9d-ef0a-53c6b7b99045"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "scores1 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "scores2 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring='recall', cv=cv, n_jobs=-1)\n",
        "scores3 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring=my_scorer, cv=cv, n_jobs=-1)\n",
        "scores4 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring=my_scorer1, cv=cv, n_jobs=-1)\n",
        "scores5 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring=my_scorer2, cv=cv, n_jobs=-1)\n",
        "scores6 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring=my_scorer3, cv=cv, n_jobs=-1)\n",
        "scores7 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "scores8 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring=my_scorer4, cv=cv, n_jobs=-1)\n",
        "scores9 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring=my_scorer5, cv=cv, n_jobs=-1)\n",
        "scores10 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring=my_scorer6, cv=cv, n_jobs=-1)\n",
        "scores11 = cross_val_score(algo, transform(X, models_mm2[10]), y, scoring=my_scorer7, cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy:',scores1)\n",
        "print('moy_accuracy:',mean(scores1))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('sensibilité :',scores2)\n",
        "print('moy_sensibilité: ',mean(scores2))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('spécificité :',scores3)\n",
        "print('moy_spécificité:',mean(scores3))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('MCC :',scores4)\n",
        "print('MCC: ',mean(scores4))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('precision-po:',scores5)\n",
        "print('moy_precision-po:', mean(scores5))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('precision-ne :',scores6)\n",
        "print('moy_precision-ne:',mean(scores6))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('AUC :',scores7)\n",
        "print('moy_AUC: ',mean(scores7))\n",
        "print(\"-------------------------------------------------\")\n",
        "print('VN :',scores8)\n",
        "print('VP :',scores9)\n",
        "print('FP :',scores10)\n",
        "print('FN :',scores11)\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\"-------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afcc9de3-04d4-4a66-a4ce-3dc775c7130c",
        "id": "ttcK3rpmnVL0"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: [0.80392157 0.76470588 0.80392157 0.80392157 0.78      ]\n",
            "moy_accuracy: 0.7912941176470589\n",
            "-------------------------------------------------\n",
            "sensibilité : [0.70967742 0.77272727 0.73333333 0.9        0.75      ]\n",
            "moy_sensibilité:  0.773147605083089\n",
            "-------------------------------------------------\n",
            "spécificité : [0.95       0.75862069 0.9047619  0.74193548 0.80769231]\n",
            "moy_spécificité: 0.8326020771960705\n",
            "-------------------------------------------------\n",
            "MCC : [0.64726859 0.52723211 0.62917039 0.6269466  0.55903777]\n",
            "MCC:  0.5979310907390006\n",
            "-------------------------------------------------\n",
            "precision-po: [0.95652174 0.70833333 0.91666667 0.69230769 0.7826087 ]\n",
            "moy_precision-po: 0.8112876254180602\n",
            "-------------------------------------------------\n",
            "precision-ne : [0.67857143 0.81481481 0.7037037  0.92       0.77777778]\n",
            "moy_precision-ne: 0.7789735449735449\n",
            "-------------------------------------------------\n",
            "AUC : [0.79274194 0.78761755 0.82857143 0.86935484 0.80608974]\n",
            "moy_AUC:  0.8168751002427308\n",
            "-------------------------------------------------\n",
            "VN : [19 22 19 23 21]\n",
            "VP : [22 17 22 18 18]\n",
            "FP : [1 7 2 8 5]\n",
            "FN : [9 5 8 2 6]\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform(X,models_mm2[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "cButKK4g7C5X",
        "outputId": "83c7c974-622b-4365-bd94-535ff6370c9e"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Min_IRM  Moy_TempJ  Amp1_TempJ  Max_TempN  VarT_ann_NDVI  Var_EVI  \\\n",
              "0       2690      14905          96      14561              2        1   \n",
              "1       3350      15360         312      14705             13        0   \n",
              "2       3350      15360         312      14705             13        0   \n",
              "3       2930      15264         306      14690              8        0   \n",
              "4       2350      15310         295      14719              1       35   \n",
              "..       ...        ...         ...        ...            ...      ...   \n",
              "249      880      14903         543      14675             52       47   \n",
              "250     1400      14838         478      14743             51        7   \n",
              "251     1080      14819         452      14666             84       70   \n",
              "252      620          0           0          0             37       40   \n",
              "253      990      14703         366      14647             77       39   \n",
              "\n",
              "     ProfAbs_Sub     IR_Moy   Bio_Tmax  Prec_Juill  Rad_Mai   Tmax_Fev  \\\n",
              "0           4143   1.968750  26.500000           1    24920  21.799999   \n",
              "1           1828   1.375000  29.700001           0    24082  22.600000   \n",
              "2           1828   1.375000  29.700001           0    24082  22.600000   \n",
              "3              0   9.304688  29.700001           0    24019  22.600000   \n",
              "4           6537   7.515625  29.900000           0    24002  22.799999   \n",
              "..           ...        ...        ...         ...      ...        ...   \n",
              "249            0  25.093750  27.700001           1    23341  15.400000   \n",
              "250          846   6.578125  27.299999           1    23582  15.500000   \n",
              "251         1729  15.914062  27.600000           1    23425  15.500000   \n",
              "252         2786  14.812500  26.799999           1    23716  17.100000   \n",
              "253         2264  30.250000  26.400000           1    23699  16.299999   \n",
              "\n",
              "     Tmax_Avril   Tmin_Oct  \n",
              "0     22.600000  18.799999  \n",
              "1     24.600000  17.799999  \n",
              "2     24.600000  17.799999  \n",
              "3     24.600000  18.100000  \n",
              "4     24.700001  18.200001  \n",
              "..          ...        ...  \n",
              "249   18.900000  16.100000  \n",
              "250   18.700001  16.799999  \n",
              "251   18.900000  16.299999  \n",
              "252   19.799999  16.299999  \n",
              "253   19.000000  15.800000  \n",
              "\n",
              "[254 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a369a7af-28c7-4723-9832-c8384cda79c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Min_IRM</th>\n",
              "      <th>Moy_TempJ</th>\n",
              "      <th>Amp1_TempJ</th>\n",
              "      <th>Max_TempN</th>\n",
              "      <th>VarT_ann_NDVI</th>\n",
              "      <th>Var_EVI</th>\n",
              "      <th>ProfAbs_Sub</th>\n",
              "      <th>IR_Moy</th>\n",
              "      <th>Bio_Tmax</th>\n",
              "      <th>Prec_Juill</th>\n",
              "      <th>Rad_Mai</th>\n",
              "      <th>Tmax_Fev</th>\n",
              "      <th>Tmax_Avril</th>\n",
              "      <th>Tmin_Oct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2690</td>\n",
              "      <td>14905</td>\n",
              "      <td>96</td>\n",
              "      <td>14561</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4143</td>\n",
              "      <td>1.968750</td>\n",
              "      <td>26.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>24920</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>18.799999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3350</td>\n",
              "      <td>15360</td>\n",
              "      <td>312</td>\n",
              "      <td>14705</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1828</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>29.700001</td>\n",
              "      <td>0</td>\n",
              "      <td>24082</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>24.600000</td>\n",
              "      <td>17.799999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3350</td>\n",
              "      <td>15360</td>\n",
              "      <td>312</td>\n",
              "      <td>14705</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1828</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>29.700001</td>\n",
              "      <td>0</td>\n",
              "      <td>24082</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>24.600000</td>\n",
              "      <td>17.799999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2930</td>\n",
              "      <td>15264</td>\n",
              "      <td>306</td>\n",
              "      <td>14690</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.304688</td>\n",
              "      <td>29.700001</td>\n",
              "      <td>0</td>\n",
              "      <td>24019</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>24.600000</td>\n",
              "      <td>18.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2350</td>\n",
              "      <td>15310</td>\n",
              "      <td>295</td>\n",
              "      <td>14719</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>6537</td>\n",
              "      <td>7.515625</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>24002</td>\n",
              "      <td>22.799999</td>\n",
              "      <td>24.700001</td>\n",
              "      <td>18.200001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>880</td>\n",
              "      <td>14903</td>\n",
              "      <td>543</td>\n",
              "      <td>14675</td>\n",
              "      <td>52</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>25.093750</td>\n",
              "      <td>27.700001</td>\n",
              "      <td>1</td>\n",
              "      <td>23341</td>\n",
              "      <td>15.400000</td>\n",
              "      <td>18.900000</td>\n",
              "      <td>16.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>1400</td>\n",
              "      <td>14838</td>\n",
              "      <td>478</td>\n",
              "      <td>14743</td>\n",
              "      <td>51</td>\n",
              "      <td>7</td>\n",
              "      <td>846</td>\n",
              "      <td>6.578125</td>\n",
              "      <td>27.299999</td>\n",
              "      <td>1</td>\n",
              "      <td>23582</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>18.700001</td>\n",
              "      <td>16.799999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>1080</td>\n",
              "      <td>14819</td>\n",
              "      <td>452</td>\n",
              "      <td>14666</td>\n",
              "      <td>84</td>\n",
              "      <td>70</td>\n",
              "      <td>1729</td>\n",
              "      <td>15.914062</td>\n",
              "      <td>27.600000</td>\n",
              "      <td>1</td>\n",
              "      <td>23425</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>18.900000</td>\n",
              "      <td>16.299999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>620</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>40</td>\n",
              "      <td>2786</td>\n",
              "      <td>14.812500</td>\n",
              "      <td>26.799999</td>\n",
              "      <td>1</td>\n",
              "      <td>23716</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>19.799999</td>\n",
              "      <td>16.299999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>990</td>\n",
              "      <td>14703</td>\n",
              "      <td>366</td>\n",
              "      <td>14647</td>\n",
              "      <td>77</td>\n",
              "      <td>39</td>\n",
              "      <td>2264</td>\n",
              "      <td>30.250000</td>\n",
              "      <td>26.400000</td>\n",
              "      <td>1</td>\n",
              "      <td>23699</td>\n",
              "      <td>16.299999</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>15.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a369a7af-28c7-4723-9832-c8384cda79c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a369a7af-28c7-4723-9832-c8384cda79c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a369a7af-28c7-4723-9832-c8384cda79c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    }
  ]
}